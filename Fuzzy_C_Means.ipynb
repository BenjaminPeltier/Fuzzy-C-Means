{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Fuzzy C-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fcm(data_mat, c, m, max_iter, init=None):\n",
    "    def calculate_centroids(data, w_mat):\n",
    "        c_mat = np.zeros((w_mat.shape[1], data.shape[1]))\n",
    "        for k in range(w_mat.shape[1]):\n",
    "            c_mat[k,:] = ((w_mat[:, k].T ** m) @ data)\n",
    "            c_mat[k,:] /= np.sum(w_mat[:, k] ** m)\n",
    "        return c_mat\n",
    "\n",
    "    def calculate_weights(data, c_mat, m):\n",
    "        w_mat = np.zeros((data.shape[0], c_mat.shape[0]))\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(c_mat.shape[0]):\n",
    "                num = norm(data[i, :] - c_mat[j, :], 2)\n",
    "                den = 0\n",
    "                for k in range(c_mat.shape[0]):\n",
    "                    den += norm(data[i, :] - c_mat[k, :], 2)\n",
    "                w_mat[i, j] = 1 / ((num / den) ** (2 / (m - 1)))\n",
    "            w_mat[i, :] /= np.sum(w_mat[i, :])\n",
    "        return w_mat\n",
    "\n",
    "    n, p = data_mat.shape\n",
    "    if not init or init==\"zeros\":\n",
    "        w_mat = np.random.rand(n, c) # np.zeros((n, c))\n",
    "    elif init==\"random\":\n",
    "        w_mat = np.random.rand(n, c)\n",
    "    else:\n",
    "        w_mat = init\n",
    "\n",
    "    c_mat = calculate_centroids(data_mat, w_mat)\n",
    "    c_mat_old = np.ones((c, p)) * np.inf\n",
    "    i = 0\n",
    "\n",
    "    while i < max_iter:\n",
    "        c_mat_old = c_mat.copy()\n",
    "        c_mat = calculate_centroids(data_mat, w_mat)\n",
    "        w_mat = calculate_weights(data_mat, c_mat, m)\n",
    "        i += 1\n",
    "\n",
    "    return w_mat, c_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(\n",
    "    n_samples=750, centers=centers,\n",
    "    cluster_std=0.4, random_state=0\n",
    ")\n",
    "X = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00413749 0.98873791 0.0071246 ]\n",
      " [0.98522263 0.00502784 0.00974953]\n",
      " [0.02648587 0.92403897 0.04947516]\n",
      " ...\n",
      " [0.25769804 0.07822054 0.66408142]\n",
      " [0.81260106 0.08452521 0.10287373]\n",
      " [0.08964194 0.04441816 0.8659399 ]]\n",
      "[[-1.31746085 -0.65536787]\n",
      " [ 0.62095235  1.3235834 ]\n",
      " [ 0.70261887 -0.65594503]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights, centroids = fcm(X, c=3, m=2, max_iter=50)\n",
    "\n",
    "print(weights)\n",
    "print(centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness :  0.944744048429382\n",
      "Homogeneity :  0.9447257027810624\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Completeness : \", metrics.completeness_score(\n",
    "    labels_true,\n",
    "    np.argmax(weights, axis=1)\n",
    "))\n",
    "\n",
    "print(\"Homogeneity : \", metrics.homogeneity_score(\n",
    "    labels_true,\n",
    "    np.argmax(weights, axis=1)\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Signification des métriques\n",
    "\n",
    " homogeneity: chaque clusters ne contient que des membres d'une seule classe.\n",
    " completeness: tous les membres d'une classe donnée sont assignés au même cluster.\n",
    "\n",
    " ## Conclusion sur l'implémentation du Fuzzy C-Means\n",
    "\n",
    " Les métriques ne sont pas faites spécifiquement pour tester les performances du clustering.\n",
    " Elles ont été utilisé en choisissant pour chaque point la classe qui avait la plus grande probabilité.\n",
    "\n",
    " Les résultats semblent très bons, plus de 90% de complitude et d'homogénéité.\n",
    " Il semblerait donc que la méthode soit bien implémentée."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
